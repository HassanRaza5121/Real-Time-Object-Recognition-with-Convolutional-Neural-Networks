# -*- coding: utf-8 -*-
"""realtime_demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rWpNkyXz4A0G0RjjNnWlxiBTiT2WonTj
"""

import cv2
import torch
import torch.nn as nn
from torchvision import transforms, models
from PIL import Image
import argparse

# -----------------------------
# Define your BaselineCNN again (same as in training)
# -----------------------------
class BaselineCNN(nn.Module):
    def __init__(self, num_classes):
        super(BaselineCNN, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),

            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
        )
        self.fc_layers = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 32 * 32, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = self.conv_layers(x)
        x = self.fc_layers(x)
        return x

# -----------------------------
# Prediction helper
# -----------------------------
def predict_frame(model, frame, transform, class_names, device):
    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    img_t = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_t)
        _, pred = torch.max(outputs, 1)

    return class_names[pred.item()]

# -----------------------------
# Main real-time demo
# -----------------------------
def main(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("Using device:", device)


    class_names = ['object1', 'object2', 'object3','object4']

    num_classes = len(class_names)

    # Select model type
    if args.model_type == "baseline":
        model = BaselineCNN(num_classes)
    elif args.model_type == "mobilenet":
        model = models.mobilenet_v2(weights=None)
        model.classifier[1] = nn.Linear(model.last_channel, num_classes)
    else:
        raise ValueError("Invalid model_type. Use 'baseline' or 'mobilenet'")

    # Load trained weights
    model.load_state_dict(torch.load(args.model_path, map_location=device))
    model.to(device)
    model.eval()
    print(f"Loaded model from {args.model_path}")

    # Transform (must match training)
    transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5])
    ])

    # OpenCV webcam capture
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("❌ Cannot open camera")
        return

    while True:
        ret, frame = cap.read()
        if not ret:
            print("❌ Failed to grab frame")
            break

        # Prediction
        label = predict_frame(model, frame, transform, class_names, device)

        # Display text on frame
        cv2.putText(frame, f"Prediction: {label}", (30, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)

        # Show video
        cv2.imshow("Real-Time Classification", frame)

        # Quit on 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# -----------------------------
# Run script
# -----------------------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_path", type=str, default="baseline_best.pth",
                        help="Path to trained model weights")
    parser.add_argument("--model_type", type=str, default="baseline",
                        choices=["baseline", "mobilenet"],
                        help="Which model architecture to use")
    args = parser.parse_args()

    main(args)